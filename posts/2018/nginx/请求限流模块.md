# ngx_http_limit_req_module
请求限流模块，用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 “leaky bucket” 

什么是漏桶算法？  
我们假设系统是一个漏桶，当请求到达时，就是往漏桶里“加水”，而当请求被处理掉，就是水从漏桶的底部漏出。水漏出的速度是固定的，当“加水”太快，桶就会溢出，也就是“拒绝请求”。从而使得桶里的水的体积不可能超出桶的容量。​主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。

一般来说漏桶算法有两种处理方式，Traffic Shaping和Traffic Policing：
1. 暂时拦截住上方水的向下流动，等待桶中的一部分水漏走后，再放行上方水。（等待）
1. 溢出的上方水直接抛弃。（丢弃）

首先配置`limit_req_zone`
```nginx
http {
  ...
  limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
  ...
}
```

上述配置表示设置了一个one的存储区，大小为10m。rate=1r/s代表允许1秒钟中处理1个请求。
 
`$binary_remote_addr`为`$remote_addr`（客户端ip）的二进制格式，固定占用4个字节。该字段说明采用客户端的ip作为判断标准来限制请求。  
1M的空间可以保存3.2万个32位的状态(1024 * 1024 / 32)，1.6万个64位的状态（1024 * 1024 / 64）  
1M的空间可以保存3.2万个32位的状态（1024*1024/32），1.6万个64位的状态()  
如果采用$remote_addr，一个ip将会占用7到15个字节，不利于存储。  
如果共享内存空间被耗尽，服务器将会对后续所有的请求返回 503错误。

接下来配置`limit_req`
```nginx
server {
  ...
  location /search {
    limit_req zone=one burst=5 nodelay;
  }
  ...
}
```
1. burst=5，设置了一个大小为5的缓冲区，当有大量请求过来，超过了访问频次（rate），这时请求会先放到缓冲区等待，而这个缓冲区的位置只有5个，超过的请求会直接报503错误。
2. nodelay
  * 如果设置了，会在瞬时提供处理(burst + rate)个请求的能力，请求超过（burst + rate）的时候就会直接返回503，永远不存在请求需要等待的情况。（这里的rate的单位是：r/s）；
  * 如果没有设置，则所有请求会一次等待排队

## Example
### 不配置burst和nodelay
```nginx
http {
  ...
  # 每分钟10个请求，每6秒处理1个请求
  limit_req_zone $binary_remote_addr zone=req_zone:1m rate=10r/m;

  server {
    listen 8888;
    server_name 127.0.0.1;

    access_log /var/logs/access.log simple_log;
    error_log /var/logs/error.log error;

    location / {
      root /Users/seed/work_space/demo/nginxDemo;
      index index.html index.htm;
      limit_req zone=req_zone;
    }
  }
  ...
}
```

使用ab测试工具，发起10个并发请求
```bash
$ ab -n 10 -c 10 http://127.0.0.1:8888/
```

ab返回结果如下：
```
Server Software:        nginx/1.13.12
Server Hostname:        127.0.0.1
Server Port:            8888

Document Path:          /
Document Length:        377 bytes

Concurrency Level:      10
Time taken for tests:   0.010 seconds
Complete requests:      10
Failed requests:        9
   (Connect: 0, Receive: 0, Length: 9, Exceptions: 0)
Non-2xx responses:      9
Total transferred:      4094 bytes
HTML transferred:       2303 bytes
Requests per second:    996.41 [#/sec] (mean)
Time per request:       10.036 [ms] (mean)
Time per request:       1.004 [ms] (mean, across all concurrent requests)
Transfer rate:          398.37 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.2      0       1
Processing:     3    7   2.4      9       9
Waiting:        2    6   2.5      7       9
Total:          4    7   2.2      9       9

Percentage of the requests served within a certain time (ms)
  50%      9
  66%      9
  75%      9
  80%      9
  90%      9
  95%      9
  98%      9
  99%      9
 100%      9 (longest request)
```
可见10个请求，只花了0.01秒，其中9个请求失败了，只有1个请求成功了

查看access.log印证一下
```
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
```

也就是说，在不配置burst和nodelay下，超过请求速率时，超过的请求都被丢弃了。  
表现在客户端为立马收到响应（503）。

### 配置burst，不配置nodelay
```nginx
server {
  listen 8888;
  server_name 127.0.0.1;

  access_log /var/logs/access.log simple_log;
  error_log /var/logs/error.log error;

  location / {
    root /Users/seed/work_space/demo/nginxDemo;
    index index.html index.htm;
    limit_req zone=req_zone burst=5;
  }
}
```

依旧发起10个并发请求，结果如下
```
Server Software:        nginx/1.13.12
Server Hostname:        127.0.0.1
Server Port:            8888

Document Path:          /
Document Length:        377 bytes

Concurrency Level:      10
Time taken for tests:   30.123 seconds
Complete requests:      10
Failed requests:        4
   (Connect: 0, Receive: 0, Length: 4, Exceptions: 0)
Non-2xx responses:      4
Total transferred:      5214 bytes
HTML transferred:       3118 bytes
Requests per second:    0.33 [#/sec] (mean)
Time per request:       30123.470 [ms] (mean)
Time per request:       3012.347 [ms] (mean, across all concurrent requests)
Transfer rate:          0.17 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       1
Processing:     2 9040 11448.4   6030   30123
Waiting:        1 9040 11448.4   6029   30123
Total:          2 9040 11448.4   6030   30123

Percentage of the requests served within a certain time (ms)
  50%   6030
  66%  12055
  75%  18078
  80%  24102
  90%  30123
  95%  30123
  98%  30123
  99%  30123
 100%  30123 (longest request)
```

10个请求，花费了30.123秒，6个请求成功了，4个请求失败了（返回503），查看access.log
```
127.0.0.1 - - [18/May/2018:17:08:58 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:58 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:58 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:58 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:08:58 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:09:04 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:09:10 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:09:16 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:09:22 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:09:28 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
```
日志中可以看到，第一个请求成功了，接下来同一时刻的（17:08:58）的4个请求都失败了，在6秒之后（2018:17:09:04）又开始成功了，之后每隔6秒返回一个请求，状态都是成功（200）。

由于设置了burst=5，服务器端收到10个并发请求，先处理第一个请求，同时将5个请求放入burst缓冲区中等待处理，而超过（burst+1）数量的请求就直接被抛弃了，即被抛弃了4个请求。

这里被放入缓冲区的请求，依照设置的速率，每隔6秒被处理一个。

表现在客户端的形态就是，第一个请求的客户端可以很快收到响应，能够被放入burst缓冲区的请求，会一直等待响应，6秒后会收到响应，剩下的那些客户端请求就立马收到503响应了。

## 配置burst，配置nodelay
```nginx
server {
  listen 8888;
  server_name 127.0.0.1;

  access_log /var/logs/access.log simple_log;
  error_log /var/logs/error.log error;

  location / {
    root /Users/seed/work_space/demo/nginxDemo;
    index index.html index.htm;
    limit_req zone=req_zone burst=5 nodelay;
  }
}
```

依旧发起10个并发请求，结果如下
```
Server Software:        nginx/1.13.12
Server Hostname:        127.0.0.1
Server Port:            8888

Document Path:          /
Document Length:        377 bytes

Concurrency Level:      10
Time taken for tests:   0.003 seconds
Complete requests:      10
Failed requests:        4
   (Connect: 0, Receive: 0, Length: 4, Exceptions: 0)
Non-2xx responses:      4
Total transferred:      5214 bytes
HTML transferred:       3118 bytes
Requests per second:    3623.19 [#/sec] (mean)
Time per request:       2.760 [ms] (mean)
Time per request:       0.276 [ms] (mean, across all concurrent requests)
Transfer rate:          1844.85 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       1
Processing:     1    1   0.4      1       2
Waiting:        0    1   0.5      1       2
Total:          1    2   0.3      2       2

Percentage of the requests served within a certain time (ms)
  50%      2
  66%      2
  75%      2
  80%      2
  90%      2
  95%      2
  98%      2
  99%      2
 100%      2 (longest request)
```
10个并发请求，0.003秒处理完，其中有6个成功，4个失败。access.log如下
```
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
```

可见，在1秒内，成功处理了6个请求（burst + 原来的处理速度）。剩下的4个请求，直接返回503错误。

也就是说配置nodelay会立马处理缓冲区中的请求。

如果在下一秒继续向服务端并发发送10个请求，服务端会拒绝这10个请求并返回503。因为我们设定了每6秒处理一个请求，在缓冲区有5个请求，因此需要等到30秒之后才能再处理一个请求。

在第一个请求的6秒之后，并发的10个请求，1个能够成功，9个失败，因为此时缓冲区的请求还没被释放，所以在这30秒内，每个6秒都能成功处理一个请求。

完整日志如下：
```
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 200 377 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:06 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"

127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
127.0.0.1 - - [18/May/2018:17:36:11 +0800] "GET / HTTP/1.0" 503 214 "-" "ApacheBench/2.3"
```

这种方式，是一种应对高并发的方式，先成功处理一批并发请求，拦截掉一批请求，然后给个缓冲的时间后再次处理新的一批并发请求。

通过这种方式，还可以让客户端不会被阻塞处理处理请求（burst缓冲区的请求不需要等待6秒才处理）。

表现在客户端的形态就是，第一个和在缓冲区的请求立马能够得到响应，而超过处理能力的请求则立马收到503。而在30秒内收到的请求都会被立马返回503。