# 散列表
散列表我们经常使用，如js里的Map，Java里的HashMap，还有redis里的HashMap，甚至redis的SortSet也是有借助散列表来实现。

由此可见，散列表的作用是多么广泛。

存储在散列表的元素具有key和value，通过散列函数（Hash 函数）将key转化为另一个值（散列值）作为散列表的key，将value存储在这个key对应的空间下。

### 使用数组实现的散列表
可以使用数组实现一个散列表。将元素的key通过散列函数映射为数组的下标，将元素的值存储在下标中。
```javascript
const names = new Array()
const userId = 101
const userName = 'Jack'

const index = hashFn(userId)
names[index] = userName
```

这里的hashFn将userId转化为数组的下标。当我们需要查找一个元素的时候，通过这个散列函数获取到下标后，就能快速的找到元素。
```javascript
const userId = 101
const index = hashFn(userId)
const userName = names[index]
```

我们知道数组下标查找元素的时间复杂度是O(1)，因此理想情况下散列表查找元素的时间复杂度也是O(1)。

但是上述例子我们也能看出两个问题：
1. 散列函数怎么写。
2. 散列函数的性能问题。

首先散列函数必须让产生的值尽可能的散开，尽可能少的产生重复的值，造成散列冲突，例如两个userId通过散列函数后产生的index是一样的，而遇到这种情况应该怎么处理。

另外就是散列函数必须轻量，不能因为散列函数影响了性能，即使散列表有O(1)的查询性能，也有可能因为散列函数被大幅度拉高。

两个相同的key经过散列函数后，产生的散列值是一定相同的。但是两个不同的key经过散列函数后，却不一定不相同。随着数组中元素的不断被填充，冲突会越来越多，因此如何解决冲突也是评判一个散列表性能的重要因素。

### 散列冲突解决
##### 线性探测
最简单的方式就是线性探测，就是在我们经过散列函数后，发现该位置已经有元素了，那么就不断往后查找，直到找到一个空闲的位置将其插入。

同理在查找元素的时候，通过散列函数转化后，如果该位置下没有元素，那么就是的确没有元素；如果有元素，那么不能马上确定这就是我们要的元素，我们还得对比里面的值是不是我们指定的值，如果不是就得不断往后遍历查找。

由此可见，恶劣情况下，我们可能需要遍历后续的整个散列表，散列表的查找性能会退化成时间复杂度为O(N)。

采用这种方案的散列表，数据量需要比较小。例如java中的ThreadLocalMap就是用了这种散列表。

当数组中的空闲位置越来越少的时候，这种情况会越来越严重，因此我们需要在数组中空闲位置少到一定程度后对数组进行扩容。由此有了如下公式
```
散列表的装载因子 = 散列表中元素的个数 / 散列表的长度
```
装载因子（load factor）越大时，说明散列表中元素的个数的越大，说明冲突会越来越严重。

也有了如下变体：
```
散列表的装载因子 * 散列表的长度 = 散列表中元素的个数
```
当装载因子固定的情况下，我们通过扩大散列表长度，调整散列表中因为存在的元素个数，当超过这个元素个数，就继续扩大长度。

例如java的HashMap的装载因子默认是0.75，如果我们散列表的长度是20，那么当散列表中的元素个数超过0.75 * 20 = 15个时就应该扩容了，一般是成倍扩展，如增大到40，此时散列表中元素个数的最大值便变为了0.75 * 40 = 30个了。

##### 链表法
这是一种使用的比较普遍的方法。如图所示：

![hashLink](../images/hash_link.jpg)

在遇到相同的hash key后，会在该位置下形成一条链表。

当插入的时候，计算出hash key后，在该位置下做链表的插入即可，这个时间复杂度是O(1)。  
当查找和删除的时候，这个时间复杂度就和链表的长度有关了，它们都需要在链表中查找到对应的元素。

这种方案，由于需要存储指针，消耗的内存大小会更大一些。

虽然在查找和删除的时候会有链表的遍历过程，但是这个比我们上面用线性探测的方式好很多，它减少了遍历的元素的个数。  
而且我们可以在链表长度到一定大小的时候将链表变成二叉树、红黑树或者跳表等更高效的查找数据结构，这样查找链表的操作就会由O(N)转化为O(logN)。

例如java中的HashMap，默认下最大装载因子为0.75，当元素超过0.75*capacity时就会开始扩容，扩容为2倍原来的大小。  
HashMap底层采用链表法来解决冲突，如果链表过长（默认为8），会引入红黑树，如果个数少于8个时，会将红黑树转化为链表，毕竟维护一颗红黑树也需要一定的性能损耗。

### 扩容策略
当散列表中数据越来越多时，装载因子会越来越大，冲突也会越来越多，此时我们需要给数组扩容，让它有更多的空闲空间。

但是重新申请一个容量更大的数组后，需要将旧的数组中的元素迁移到新的数组中，而且迁移过程中需要不断重新计算哈希值。

常见的情况就是，当我们插入一个元素后，装载因子刚好达到扩容的阈值，于是便开始扩容，如果数据量很大，扩容的时间就会很长，导致我们的插入数据消耗的时间被拉长，本来一个O(1)的性能，变得难以接受。

因此，在数据量非常大的时候就不适合这种一次性扩容方案了，我们可以分批完成扩容。当插入数据而启动扩容时，可以将老的散列表中的其中一个数据迁移到新的散列表中，这样每次只迁移一个，这样也让我们的插入操作变得非常快了。

查询的话，需要现在新的散列表中查找，如果没找到再去老的散列表中查找，效率也就非常高。

### 使用场景
#### redis有序集合
redis有个有序集合，它可以在一个集合中给一个key添加一个数值，然后对集合进行排序，它有如下特点：
1. 添加一个对象
2. 按照键值来删除一个对象
3. 按照键值查找对象
4. 按照分值区间查找数据，比如查找[40, 80]的数据
5. 按照分值从小到大排序

看看具体在redis中的用法
```
$ ZADD page_rank 10 google.com
$ ZADD page_rank 9 baidu.com 8 bing.com
$ ZRANGE page_rank 0 -1 WITHSCORES
1) "bing.com"
2) "8"
3) "baidu.com"
4) "9"
5) "google.com"
6) "10"
$ ZADD page_rank google.com
10
```

如果实现一个简单的这种有序集合的功能，应该怎么做呢？

首先，我们可以使用跳表来实现按照分值查询区间的数据，跳表中，key为分数，值为指向对象的指针。这样我们只需要通过跳表的方式便可以遍历到我们要的数据，而跳表的时间复杂度为O(logN)。

但是我们还需要通过key来查找元素，如上面例子中的`ZADD page_rank google.com`，由于跳表的key是分值，所以无法使用，只能去遍历跳表的原始数据，如果我们跳表索引数据下原始数据存储的方式是用链表的话，我们就得遍历链表，这个时间复杂度就是O(N)了。

我们可以将链表替换成散列表，通过散列表就能在O(1)的性能下获取到数据了。将键值对象，通过散列表的方式存储，加快查询和删除的性能，同时使用跳表来实现区间读取。

#### 图库图片搜索
如何在在海量的图库中搜索一张图片是否存在。  

首先需要定义图片的唯一标识，可以获取图片的二进制数据，可以只取二进制数据的前100个字节，中间的100字节和最后的100字节，组成300字节的数据，然后通过哈希算法得到一个哈希字符串，作为图片的唯一标识。

将这个唯一标识和图片在图库中的路径作为key、value，存储在散列表中。

当我们需要查询图片是否在图库中，先通过哈希算法得到图片的唯一标识后，在散列表中查询：  
1. 如果查询不到，说明图库中不存在该图片
2. 如果查询到了，那么获取散列表中记录的图片路径，将这个路径和查询提供的路径进行比较
    * 如果一样，说明图库中存在该图片
    * 如果不一样，说明图库中存在一张唯一标识一样，但是并不是相同的图片

##### 进阶版
当图片非常多，如上亿张图片时，如果只在一台机器上实现上面的方法显然是行不通的，单台机器的内存有限，通过散列表是无法存储这么海量的数据的。

因此我们需要对数据进行分片，将数据分发到多台机器进行处理，每台机器负责维护部分图片。

如何将图片分发到各个机器呢？
1. 可以先逐个获取图库的图片，计算唯一标识，然后对机器个数n取模，这个值就是对应的机器编号。
2. 将这个图片的唯一标识和路径发到对应机器上，存储在散列表中。

查询图片是否在图库中：通过相同的哈希算法，计算图片唯一标识，与机器个数取模，假设值为n，则去编号为n的机器查找即可，查找流程和之前的是一样的。

##### 再次进阶版
当图片的数量在海量的基础上还在继续增长，我们可以不断的加机器解决，但是问题来了。我们知道，我们是通过与机器个数取模，来获取处理机器的编号，当机器个数变化了，模也对应变了。

例如，假设有个图片的唯一标识为15，机器个数为10，那么取模后为5，那么就去编号为5的机器上查找图片。

当我们机器增加了1台，变为11了，此时取模变为了4。这时候去编号4的机器上查找图片肯定是没查到的，如果我们图库的所有数据都存储在数据库中，由于在机器的内存上找不到数据，就会直接请求数据库，这时候大量的请求就会直接落在了数据库上，导致了严重的缓存穿透。

因此这时候需要将所有数据重新计算模值，重新分发到对应的机器上，但是这个分发操作是很吃力和耗时的，如果每次加机器都要做一次全量更新，显然不是很合理。

有没有一种方式不需要做全量的数据迁移呢，这就是一致性哈希算法的作用了。

这篇动画可以简单的理解 [一致性哈希](https://www.sohu.com/a/158141377_479559)

一致性哈性会定义一个槽位数量，例如在redis里总共有2^32=16384个槽位。

这里我们可以设置小一点，假设为60个槽位，我们一开始只有3台机器，我们通过对机器的ip做哈希并取模，分发机器到各个槽位上：  
hash(ip)%60

假设3台机器A、B、C，分别被分发到了15、37和46这三个槽位上。

接下来同理分发图片：  
hash(imageId)%60

假设有3张图片被分发到5、30和50槽位上，那这3个槽位都没有机器，怎么办呢。此时便顺时针寻找，找到的第一个机器就是它的所属机器，于是这3张图片，分别对应的机器便是15、37、15上。

当我们加了一台机器D，它在33号槽位上，此时只需要将第二张图片从机器B移动到D上即可，其他图片都不需要做变动。

通过这种方式我们就减少了移动的数据量，这也是一致性哈性广泛应用在分布式系统的原因。

### 总结
总结一下，如果我们自己设计一个散列表，需要具备的特性：
1. 拥有快速的查询、增加和删除的性能
2. 内存占用合理，不能占用过多的内存空间
3. 性能稳定，在极端情况下，性能也不能退化到无法接受的情况

由此，我们需要：
1. 设计一个合理的散列函数
2. 合理设置装载因子的阈值，并且有合理的扩容策略
3. 合理的散列冲突解决方案

看看golang是怎么使用散列表的
```go
user := make(map[string]string, 10)
user["u1"] = "Jack"
user["u2"] = "Jack"
```
golang的使用散列表非常简洁，通过make和map就能定义一个散列表，那它底层是怎么实现的呢？

golang采用的是HashMap来实现散列表，具体源码在`runtime/hashmap.go`下

详细细节描述可以参考 [解剖Go语言map底层实现](https://blog.csdn.net/i6448038/article/details/82057424) 


### 思考题
#### word文档中单词拼写检错功能实现
我们常用的英文单词也就几十万，假设为20万，单词的平均长度为10个字母，那么一个单词占用10个字节，20万个单词约占用2M，简直微不足道的内存空间，直接使用散列表即可实现这个功能。
```javascript
const map = new Map()
map.set('hello', 1)
map.set('word', 1)

if (map.get('hello')) {
  console.log('hello is exist')
} else console.log('hello is not exist')

```
如果在散列表中单词不存在，说明我们拼写错误。

#### 两个字符串数组，每个数组大约有10万条字符串，快速找出两个数组中相同的元素。
将大的那个数组塞入一个散列表中，然后遍历另外一个数组，去散列表中查找是否存在，遍历的时间复杂度是O(N)，查找的时间复杂度是O(1)，因此整个过程只需要O(N)的时间。
```javascript
const arr1 = [1,2,3,4,5]
const arr2 = [2,3,6]

const map = new Map()
for(let i = 0; i < arr1.length; i++) {
  map.set(arr1[i], 1)
}

const sameElements = []
for(let i = 0; i < arr2.length; i++) {
  if (map.get(arr2[i])) {
    sameElements.push(arr2[i])
  }
}
```

#### 有10万条URL访问日志，如何按照访问次数给URL排序
将URL作为key，访问次数为value存入散列表，遇到相同的URL，访问次数就加1，不断记录这个URL最大访问次数。

最终会有一个散列表，和一个每个URL的访问次数组成的数组，然后用排序算法进行排序即可
```javascript
const urls = []
const map = new Map()
for(let i = 0; i < urls.length; i++) {
  let accessCount = map.get(urls[i])
  if (accessCount) {
    map.set(urls[i], urls[i]++)
  } else {
    map.set(urls[i], 1)
  }
}

// sort with hash table
```
