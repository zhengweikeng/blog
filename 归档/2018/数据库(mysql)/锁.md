# 锁
## 全局锁
全局锁就是对整个数据库实例加锁，加锁之后，数据操作语句（DML）、数据定义语句（DDL）和更新类事务的提交语句，这些语句都会被阻塞。

加全局锁的命令如下：
```sql
Flush tables with read lock;
```

使用全局锁，一般是需要做全库逻辑备份的时候，但是这个时候整个数据库都会处于只读状态。

真正需要全库备份的时候，我们不会用它来做。我们知道在事务的隔离级别里，有一个叫**可重复读**，它会保证在事务期间，读取的数据都是一致的。借助它就可以在我们需要备份的时候，开启一个隔离级别为可重复读的事务来进行备份操作。mysql有个逻辑备份工具**mysqldump**可以做到
```sql
mysqldump -uroot -p123 --single-transaction db1 > db.sql;
```

但是这种方式只能用在支持事务的引擎，如InnoDB。如果使用的是MyISAM就不支持事务，因此无法使用`--single-transaction`，只能使用全局锁的方式进行备份。

既然全局锁是让全库只读，那设置数据库为只读状态的，还可以这样做` set global readonly=true`，但是我们不会这么做。    
主要是设置global的影响比较大，设置之后如果客户端发生异常，这时候数据库会一直处于readonly状态，导致数据库一直处于不可写的状态，风险很高。  
但是如果用全局锁的方式，如果客户端发生异常断开，这时数据库会自动释放这个全局锁，数据库便能恢复正常。

## 表锁
顾名思义，锁的是单张表，命令如下：
```sql
lock tables ... read/write;

unlock tables;
```

数据库中建立一张引擎为MyISAM的表user，通过它来模拟加锁的情形。
```sql
CREATE TABLE `user` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
```

### 读锁
接下来，我们分别建立两条连接到数据库，称为线程A和线程B

时间 | 线程A | 线程B
---------|----------|---------
 1 | LOCK TABLES user READ; (对user表加读锁) |
 2 | SELECT * FROM user; (读数据正常) | SELECT * FROM user; (读数据正常)
 3 | INSERT INTO user(name) VALUES('Pink'); (直接报错，Table 'user' was locked with a READ lock and can't be updated) | INSERT INTO user(name) VALUES('Jim'); (阻塞并等待线程A释放锁)
 4 | UNLOCK TABLES; | 阻塞的insert语句得到执行
 5 | LOCK TABLES user READ LOCAL; (对user表加读锁，用 local修饰) | 
 6 | INSERT INTO user(name) VALUES('Zhangsan'); (直接报错，Table 'user' was locked with a READ lock and can't be updated) | INSERT INTO user(name) VALUES('Tim'); (语句正常执行，写入成功)
 7 | SELECT * FROM user; (查询不到线程B写入的数据Tim) | 
 8 |  | UPDATE user SET name='Tim2' WHERE name = 'Tim'; (更新被阻塞)
 9 | UNLOCK TABLES; | 上述更新被执行
 Table 'user' was locked with a READ lock and can't be updated

 这里还有个情况，当使用表锁将表锁定后，也就不能读写其他表了
 ```sql
> LOCK TABLES user READ;
> SELECT * FROM grades;
error: Table 'grades' was not locked with LOCK TABLES
 ```

### 写锁
同理，我们分别建立两条连接到数据库，称为线程A和线程B
 
时间 | 线程A | 线程B
---------|----------|---------
1 | LOCK TABLES user WRITE; (加表写锁) | 
2 | SELECT * FROM user; (查询正常) | C2
3 | INSERT INTO user(name) VALUES ('lisi'); (写入成功) | SELECT * FROM user; (阻塞，等待表写锁释放)
4 | UNLOCK TABLES; | 上述阻塞语句得到执行，写入成功

### 元数据锁(metadata lock，MDL)
这种锁是mysql在5.5的版本中引入的，通过事务的方式保护数据。MDL不需要显示使用，在访问一个表的时候会自动被加上。

想象一下，当你执行一个查询，在查询过程中，另一个线程删除了某一列，那么查询线程拿到的数据就跟表结构对不上了。因此mysql引入MDL解决这种情况，当对一个表做增删改查时，加MDL读锁；当对表结构变更操作的时候，加MDL写锁。
1. 读锁之间不互斥，因此可以在不同线程之间对同一个表进行增删改查
2. 读写锁之间，写锁之间是互斥的，因此如果有两个线程，一个读取数据，一个修改表结构，读取的线程需要等待修改表结构的线程执行完成后才可以执行。

需要注意的是，使用MDL锁也可能会有引发大面积的阻塞，看下面的例子

我们重新建立user表，这次用InnnoDB的引擎
```sql
CREATE TABLE `user` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=4;
```

线程A | 线程B | 线程C | 线程D
---------|----------|---------|---------
start TRANSACTION;| start TRANSACTION;| start TRANSACTION;| start TRANSACTION;
select * from user limit 1; | /  | / | /
/ | / | alter table user add age int; (block) | /
/ | / | / | select * from user limit 1; (block)

4个线程都在对表user做操作，线程A和B都会对表user加MDL读锁，两者不互斥。  

但是线程C却block了，因为线程A的MDL读锁还没被释放，而C是需要MDL写锁，因此只能等待。  

到了线程D，它也被block了，因为它需要拿到MDL读锁，但是这些新申请的锁都因为线程C被阻塞了。

接下来如果还有大量查询进来的话，也都会被block住，导致数据库最终被撑爆。

这里4个线程代表4个事务，即使语句已经执行结束了，锁并不会被释放（如线程A的查询语句），需要等到事务提交后才会被释放。

虽然我们表里没有一条数据，只是做了一个加字段的操作，也引发了数据库性能问题，那如何给一张表加字段才能避免这种情况呢？

这里的问题就是事务导致的，事务没有结束，MDL锁就不会被释放，只要让事务结束就能避免这种情况了。  
在执行DDL变更表结构前，可以先去`information_schema`库中查看`innodb_trx`表中查看事务是否存在长事务，如果存在的话，可以考虑先暂停DDL操作，或者先把长事务干掉。

但是有时把长事务干掉也不见得管用，例如在一些热点数据的查询时，旧的长事务被干掉了，新的又来了。  
一种比较好的方式是在DDL里添加超时功能，如果在一定时间内都无法拿到MDL锁，则先放弃执行，这样不会阻塞后续语句的执行。然后再进行重试，反复这个过程。

AliSQL已经有这个动能了，而且MariaDB也整合了这个功能
```sql
alter table t nowait add column;
alter table t wait add column;
```

通过加表锁，可以在一定程度上处理一些并发问题，但是这种代价还是有些大，尤其写锁。  

例如，我们只是要更新一条数据，加了表锁后，其他线程想要读取其他数据也被阻塞了。

注意到我们上面建的表是MyISAM类型的，这种引擎的表只能通过表锁的方式进行并发控制，但是如果使用InnoDB类型的话，我们就可以通过事务和行级锁的方式来做，这就是为什么我们推荐使用InnoDB引擎的原因。

## 行级锁
InnoDB支持行级锁，可以让锁只加在待操作的行上，这样对其他行记录的操作就不会被阻塞了。
```sql
CREATE TABLE `user` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_name` (`name`)
) ENGINE=InnoDB AUTO_INCREMENT=4;

insert into user(name) values('zhangsan');
insert into user(name) values('jack');
```
注意这里，我们给字段name加了索引，加了索引才能使用行锁。

表user目前有一条数据
id | name 
---------|----------
 1 | zhangsan
 2 | jack

然后我们分别用两个线程，各自开启事务进行如下操作： 

线程A | 线程B
---------|----------
 start TRANSACTION; | start TRANSACTION;
 select * from user where id = 1; (成功执行) | update user set name='lisi' where id = 1; (成功执行)
 select * from user where id = 2; (成功执行) | - 
 update user set name='tim' where id = 2; (成功执行) | -
 update user set name='wangwu' where id = 1; (block) | -
  上述update得到执行 | commit
  commit | -

线程B在执行update后，给id=1的行记录加上了行锁，线程A在更新id=2的时候是成功的，但是更新id=1时被阻塞了，说明这行被锁住了，只有线程B的事务提交了锁才会被释放，被阻塞的线程A才能得到执行。

```sql
drop index idx_name;
```

假设现在表里数据还是如下：
id | name 
---------|----------
 1 | zhangsan
 2 | jack


开始做如下操作

线程A | 线程B
---------|----------
 start TRANSACTION; | start TRANSACTION;
 select * from user where name = 1; (成功执行) | update user set name='zs' where name = 'zhangsan'; (成功执行)
 update user set name='jk' where name = 'jack'; (block) | -
  上述update得到执行 | commit
  commit | -

可见线程B执行update后，线程A接下来更新了一条和B不一样的记录，但是却被block了，说明此时表被锁住了。

## 死锁
如下语句

事务A | 事务B 
---------|----------
 begin | begin
 update t set k=k+1 where id=1; | /
 / | update t set k=k+1 where id=2;
 update t set k=k+1 where id=2; | /
 / | update t set k=k+1 where id=1;

当事务A执行到第二条update语句时，它需要等待事务B释放id=2的行锁；   
当事务B执行到第二条update语句时，它需要等待事务A释放id=1的行锁；   

这时就导致了死锁。有两种方式解决：
1. 互相等待，直到超时。通过超时参数`innodb_lock_wait_timeout`配置获取锁的超时时间，默认值是50s。
2. 一旦发现死锁，强制回滚其中一个事务，让另一个事务能够继续执行。通过参数`innodb_deadlock_detect=on`开启这个功能。但是这种检测需要耗费大量的CPU资源。

## 思考
**当备库用–single-transaction 做逻辑备份的时候，如果从主库的binlog传来一个DDL语句会怎么样？**
```sql
Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
/* other tables */
Q3:SAVEPOINT sp;
/* 时刻 1 */
Q4:show create table `t1`;
/* 时刻 2 */
Q5:SELECT * FROM `t1`;
/* 时刻 3 */
Q6:ROLLBACK TO SAVEPOINT sp;
/* 时刻 4 */
/* other tables */
```
上述sql语句模拟了从库备份的过程，Q1先确保数据库的隔离级别为可重复读，然后Q2开启一个事务。之后Q3设置一个保存点，Q4拿到了表结构，Q5开始导数据，Q6回滚到保存点，释放t1的MDL锁。

binlog的到来，根据不同时间阶段会有不同提现。
* 如果是Q4执行之前到达，则没有任何影响，Q4执行后拿到的是DDL后的表结构
* 如果是在时刻2到达，此时表结构已经变化，Q5的执行会报错
* 如果在时刻2和时刻3之间到达，此时t1被加上MDL读锁，binlog被阻塞，直到Q6执行完成。
* 如果是在时刻4达到，t1的MDL读锁已经被释放，因此没有任何影响，备份拿到的是DDL之前的表结构。

**删除一个表里面的前10000行数据**
有如下三种：
1. `delete from t limit 10000;`
2. 在一个连接中循环执行20次`delete from t limit 500;`
3. 在20个连接中同时执行 `delete from t limit 500;`

第一种方式，单个语句的执行时间长，锁的占用时间也比较长，而且大事务还会导致主从延迟  

串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性。

第三种方式，连接太多，有可能造成锁冲突。

相对而言，第二种方式较好。
